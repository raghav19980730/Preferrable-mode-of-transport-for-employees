glm(df$Species~df$Sepal.Length,family = 'binomial')
?glm()
glm(df$Species~df$Sepal.Length + df$Sepal.Width)
glm(df$Species~.,data = df)
model <- glm(df$Species~.,data = df)
summary(model)
predict(model,df)
df
df = iris
View(df)
model <- glm(df$Species~.,data = df)
model <- glm(df$Species~ df$Sepal.Length)
library(nnet)
df = iris
model <- multinom(df$Species~ df$Sepal.Length)
model <- multinom(Species~., data = df)
df = iris
model <- multinom(Species~., data = df)
summary(model)
levels(df$Species)
predict(model,df)
df$pre <- predict(model,df)
df$pred <- predict(model,df)
table(df$Species,df$pred)
library(c(car,caret)
library(c(car,caret))
library(car)
llibrary(caret)
library(caret)
library(tidyverse)
summary(model)
model <- multinom(Species~., data = df)
summary(model)
View(df)
model <- multinom(Species~., data = df)
installed.packages('glmnet')
install.packages('glmnet')
library(glmnet)
set.seed(42)
n <- 1000
p <- 5000
real_p <- 15
x <- matrix(rrnorm(n*p), nrow = n, ncol = p)
x <- matrix(rnorm(n*p), nrow = n, ncol = p)
y <- apply(x[,1:real_p],1,sum) + rnorm(n)
train <- sam(1:n,.66*n)
train <- sample(1:n,.66*n)
x.train <- x[train,]
x.test <- x[-train,]
y.train <- y[train,]
y.train <- y[train]
y.test <- y[-train]
modelo.fit <- cv.glmnet(x.train,y.train,type.measure = 'mse',
alpha = 0,family= 'gaussian')
model0.fit <- cv.glmnet(x.train,y.train,type.measure = 'mse',
alpha = 0,family= 'gaussian')
pred <- predict(model0.fit, s=model0.fit$lamda.1se,newx = x.test)
model0.fit <- cv.glmnet(x.train,y.train,type.measure = 'mse',
alpha = 0,family= 'gaussian')
model0.fit$lambda
model0.fit$lambda.1se
model0.fit$lambda.min
pred <- predict(model0.fit, s=model0.fit$lambda.min,newx = x.test)
mean((y.test - pred)^2)
pred0 <- predict(model0.fit, s=model0.fit$lambda.min,newx = x.test)
#Lasso
model1.fit <- cv.glmnet(x.train,y.train,type.measure = 'mse',
alpha = 1,family= 'gaussian')
pred1 <- predict(model1.fit, s=model1.fit$lambda.min,newx = x.test)
mean((y.test - pred1)^2)
#Net
modelnet.fit <- cv.glmnet(x.train,y.train,type.measure = 'mse',
alpha = 0.5,family= 'gaussian')
prednet <- predict(modelnet.fit, s=modelnet.fit$lambda.min,newx = x.test)
mean((y.test - prednet)^2)
#Different values of alpha
list_net <- list()
for (i in 0:10){
fit_name = paste0("alpha:",i/10)
list_net[[fit_name]] = cv.glmnet(x.train,y.train,type.measure = 'mse',
alpha = i/10,family= 'gaussian')
}
results <- data.frame()
for ( i in 0:10){
fit_name = paste0('alpha:',i/10)
predicted = predict(list_net[[fit_name]], s=list_net[[fit_name]]$lambda.1se,newx = x.test)
mse = mean((y.test - predicted)^2)
temp = data.frame("alpha" = i/10,'mse' = mse,'fit_name' = fit_name)
}
temp
for ( i in 0:10){
fit_name = paste0('alpha:',i/10)
predicted = predict(list_net[[fit_name]], s=list_net[[fit_name]]$lambda.1se,newx = x.test)
mse = mean((y.test - predicted)^2)
temp = data.frame(alpha = i/10,mse = mse,fit_name = fit_name)
}
results <- rbind(results,temp)
results
list_net
list_net[[1]]
predicted
for ( i in 0:10){
fit_name = paste0('alpha:',i/10)
predicted = predict(list_net[[fit_name]], s=list_net[[fit_name]]$lambda.1se,newx = x.test)
mse = mean((y.test - predicted)^2)
temp = data.frame(alpha = i/10,mse = mse,fit_name = fit_name)
results = rbind(results,temp)
}
results
summary(model1.fit)
model1.fit
model1.fit$cvm
model1.fit$glmnet.fit
model1.fit
require(data.table)
require(glmnet)
set.seed(123)
###reading data
housingData=fread('data/kc_house_data.csv')
model1.fit$cvlo
model1.fit$glmnet.fit
model1.fit$glmnet.fit$beta
model1.fit$glmnet.fit$beta[,model1.fit$glmnet.fit$lambda == model1.fit$lambda.1se]
#Regression
#Hyperparameter tuning
#Different values of alpha
library(glmnet)
?cv.glmnet
#Using caret package
library(caret)
seq(0,1,0.1)
library(gbm)
?gbm
library(rpart)
?rpart
Values = c(1488.809802,521.884604,0.000000,8.140911,482.474551,4.840826,1314.805256,1252.944053)
col = c('Age','Distance','Engineer','Gender','license','MBA','Salary','Work.Exp')
data.frame(col,Values)
y = data.frame(col,Values)
plot(y)
?plot(y)
y = data.frame(col,Values,type ='p')
y = data.frame(col,Values)
plot(y,type = 'p')
?plot
plot(x = y$Values, y=y$col,type = 'p')
y = sort(y$Values,decreasing = TRUE)
plot(x = y$Values, y=y$col,type = 'p')
y
y = sort(data.frame(col,Values),decreasing = TRUE)
?order()
?plot
y = data.frame(col,Values)
y[order(y$Values),]
?order
y[order(y$Values,decreasing = T),]
y = y[order(y$Values,decreasing = T),]
plot(x = y$Values, y=y$col,type = 'p')
line(y$Values)
lines(y$Values)
?lines()
lines(y = y$Values)
lines(x =y$col y = y$Values)
lines(x =y$col,y = y$Values)
plot(x = y$Values, y=y$col,type = 'p')
lines(x =y$col,y = y$Values)
lines(y=y$col,x = y$Values)
plot(x = y$Values, y=y$col,type = 'p')
lines(y=y$col,x = y$Values)
plot(x = y$Values, y=y$col,type = 'l')
plot(x = y$Values, y=y$col,type = 'l')
y = y[order(y$Values,decreasing = T),]
y
plot(x = y$Values, y=y$col,type = 'p')
y = data.frame(col,Values)
y = y[sort(y$Values,decreasing = T),]
y
?reorder()
library(ggplot2)
setwd("C:/Users/ragha/Desktop/Raghav/Great Learning/Projects/Project 5")
library(readxl)
library(corrplot)
library(class)
library(gridExtra)
library(tidyverse)
library(car)
library(class)
library(caret)
library(ROCR)
library(ineq)
library(dplyr)
library(broom)
library(caTools)
library(DMwR)
library(xgboost)
library(ipred)
library(rpart)
library(gbm)
churn <- read.csv('Cars.csv')
head(churn)
tail(churn)
str(churn)
summary(churn)
churn$Gender <- factor(churn$Gender,levels = c('Male','Female'), labels = c(0,1))
churn$Engineer <- as.factor(churn$Engineer)
churn$MBA <- as.factor(churn$MBA)
churn$license <- as.factor(churn$license)
prop.table(table(churn$Transport))*100
#Histogram
par(mfrow = c(2,2))
for(i in names(churn[-c(2,3,4,8,9)])){
hist(churn[,i], xlab = names(churn[i]), col = "red", border = "black", ylab = "Frequency",
main =paste("Histogram of", names(churn[i])),col.main = "darkGreen")
}
par(mfrow = c(1,1))
#Barplot
table1 <- churn %>% group_by(Transport,Gender) %>% summarise("Values" = n())
table1[c(1,2)] <- lapply(table1[c(1,2)], as.factor)
A <- ggplot(table1,aes(Gender,Values,fill = Transport)) + geom_bar(stat = "identity",color = "Black", position = 'dodge')+
geom_text(aes(label = Values),
size = 3,
color = "black",
position = position_dodge(width = 0.9),
vjust = -0.2)
table2 <- churn %>% group_by(Transport,MBA) %>% summarise("Values" = n())
table2[c(1,2)] <- lapply(table2[c(1,2)], as.factor)
B <- ggplot(data = table2, aes(MBA,Values, fill = Transport)) + geom_bar(stat = 'identity', position = 'dodge',color = "Black")+
geom_text(aes(label = Values),
size = 3,
vjust = -0.2,
position = position_dodge(width = 0.9))
table3 <- churn %>% group_by(Transport,'License' = license) %>% summarise("Values" = n())
table3[c(1,2)] <- lapply(table3[c(1,2)], as.factor)
C <- ggplot(table3,aes(License,Values,fill = Transport)) + geom_bar(stat = "identity",color = "Black", position = 'dodge')+
geom_text(aes(label = Values),
size = 3,
color = "black",
position = position_dodge(width = 0.9),
vjust = -0.2)
table4 <- churn %>% group_by(Transport,Engineer) %>% summarise("Values" = n())
table4[c(1,2)] <- lapply(table4[c(1,2)], as.factor)
D <- ggplot(data = table4, aes(Engineer,Values, fill = Transport)) + geom_bar(stat = 'identity', position = 'dodge',color = "Black")+
geom_text(aes(label = Values),
size = 3,
vjust = -0.2,
position = position_dodge(width = 0.9))
grid.arrange(A,B,C,D)
#Boxplot
A <- ggplot(data = churn, aes(as.factor(Transport),Age)) + geom_boxplot(color = c("Red","Blue","Green")) + xlab("Transport") + ggtitle("Age vs Transport")
B <- ggplot(data = churn, aes(as.factor(Transport),Work.Exp)) + geom_boxplot(color = c("Red","Blue","Green")) + xlab("Transport") + ggtitle("Work Experience vs Transport")
C <- ggplot(data = churn, aes(as.factor(Transport),Salary)) + geom_boxplot(color = c("Red","Blue","Green")) + xlab("Transport") + ggtitle("Salary vs Transport")
D <- ggplot(data = churn, aes(as.factor(Transport),Distance)) + geom_boxplot(color = c("Red","Blue","Green")) + xlab("Transport") + ggtitle("Distance vs Transport")
grid.arrange(A,B,C,D)
par(mfrow =c(1,1))
#Missing values
any(is.na(churn))
colSums(is.na(churn))
churn <- na.omit(churn)
#Outlier Detection and Treatment
#Cooks distance for outliers detection
cooksd <- cooks.distance(glm(as.numeric(Transport)~.,data = churn))
plot(cooksd,pch="*", cex =1, main ="Cook's Distance", col ="blue")
abline(h = 4*mean(cooksd, na.rm = TRUE), col = "DarkRED",lwd = 2)
#Any value above red line  indicates influential values or outliers
#Treatment using mean imputation method
mydata <- churn[,c(1,5:7)]
Outliers<- mydata[1:60,]
for(i in c(1:4)) {
Outliers[,i] <- NA
Box <-boxplot(mydata[,i],plot =F)$out
if (length(Box)>0){
Outliers[1:length(Box),i] <- Box
}
}
for(i in names(mydata[c(1,2,4)])){
q = quantile(mydata[,i])
mydata[mydata[,i] > q[[4]] + 1.5*(q[[4]] - q[[2]]) ,i ] <- round(q[[4]] + 1.5*(q[[4]] - q[[2]]))
}
q = quantile(mydata[,'Salary'])
mydata[mydata$Salary > q[[4]] + 3*(q[[4]] - q[[2]]),'Salary'] <- round(q[[4]] + 3*(q[[4]] - q[[2]]))
churn <- cbind.data.frame(mydata,churn[,c(2:4,8,9)])
max(churn$Distance)
### Converting dependent variable into 2 levels
churn$Transport <- ifelse(churn$Transport == "Car",1,0)
churn$Transport <- as.factor(churn$Transport)
#Multicollinearity
cor <- cor(churn[c(1:4)])
corrplot.mixed(cor,lower = "number", upper = "pie")
#Variance Inflation Factor
vif(glm(as.numeric(Transport)~., data = churn))
vif(glm(as.numeric(Transport)~. -Work.Exp, data = churn))
#vif < 5. No significant evidence to treat multicollinearity
#Bagging
bag.churn <- churn
set.seed(100)
split <- sample.split(bag.churn$Transport,SplitRatio = 0.75)
smote.train <- bag.churn[split == TRUE,]
bag.train <- SMOTE(Transport~., data = smote.train,perc.over = 3000, k=5,perc.under = 150)
bag.test <- bag.churn[split == FALSE,]
bag.model<- bagging(Transport ~.,
data=bag.train,
control=rpart.control(maxdepth=5, minsplit=4))
ggplot(varImp(bag.model))
ggplot(varImp())
bag.model %>% ggplot(varImp())
ggplot2::ggplot(varImp(bag.model))
plot(bag.model)
RocImp2 = varImp(bag.model,scale = FALSE)
RocImp2 = varImp(bag.model)
write.csv(RocImp2, file = 'RocImp2.csv')
VIMP <- read.csv('RocImp2.csv')
plot(VIMP)
VIMP
ggplot(VIMP) + geom_bar(aes(x = Age, y = Overall))
ggplot(VIMP) + geom_bar(aes(x = X, y = Overall))
ggplot(VIMP,stat ='identity') + geom_bar(aes(x = X, y = Overall))
ggplot(VIMP) + geom_bar(aes(x = X, y = Overall),stat ='identity')
ggplot(order(VIMP,decreasing = T)) + geom_bar(aes(x = X, y = Overall),stat ='identity')
ggplot(VIMP) + geom_bar(aes(x = X, y = sort(Overall)),stat ='identity')
VIMP
ggplot(VIMP) + geom_bar(aes(x = X, y = order(Overall)),stat ='identity')
ggplot(VIMP) + geom_bar(aes(x = X, y = overall),stat ='identity')
ggplot(VIMP) + geom_bar(aes(x = X, y = Overall),stat ='identity')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall),stat ='identity')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall, col = X),stat ='identity')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall, fill = X),stat ='identity')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall, fill = X),stat ='identity') +
xlab('Variables') + y('Importance')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall, fill = X),stat ='identity') +
xlab('Variables') + ylab('Importance')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall),fill= 'Blue',stat ='identity') +
xlab('Variables') + ylab('Importance')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall),fill= 'LigthBlue',stat ='identity') +
xlab('Variables') + ylab('Importance')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall),fill= 'LightBlue',stat ='identity') +
xlab('Variables') + ylab('Importance')
ggplot(VIMP) + geom_bar(aes(x = reorder(X,-Overall), y = Overall),fill= 'LightBlue',stat ='identity') +
xlab('Variables') + ylab('Importance') +ggtitle('Variable Importance')
bag.model$X
bag.model$mtrees
bag.model$mtrees[0]
bag.model$mtrees[1]
bag.model$mtrees[[1]]
rpart(bag.model$mtrees[[1]])
rpart.plot(bag.model$mtrees[[1]])
library(rpart.plot)
rpart.plot(bag.model$mtrees[[1]])
rpart.plot(bag.model)
plot(bag.model)
plot(bag.model$mtrees)
plot(bag.model$mtrees[1])
plot(bag.model$mtrees[[1]])
setwd("C:/Users/ragha/Desktop/Raghav/Great Learning/Projects/Project 5")
library(readxl)
library(corrplot)
library(class)
library(gridExtra)
library(tidyverse)
library(car)
library(class)
library(caret)
library(ROCR)
library(ineq)
library(dplyr)
library(broom)
library(caTools)
library(DMwR)
library(xgboost)
library(ipred)
library(rpart)
library(gbm)
churn <- read.csv('Cars.csv')
head(churn)
tail(churn)
str(churn)
summary(churn)
churn$Gender <- factor(churn$Gender,levels = c('Male','Female'), labels = c(0,1))
churn$Engineer <- as.factor(churn$Engineer)
churn$MBA <- as.factor(churn$MBA)
churn$license <- as.factor(churn$license)
prop.table(table(churn$Transport))*100
#Histogram
par(mfrow = c(2,2))
for(i in names(churn[-c(2,3,4,8,9)])){
hist(churn[,i], xlab = names(churn[i]), col = "red", border = "black", ylab = "Frequency",
main =paste("Histogram of", names(churn[i])),col.main = "darkGreen")
}
par(mfrow = c(1,1))
#Barplot
table1 <- churn %>% group_by(Transport,Gender) %>% summarise("Values" = n())
table1[c(1,2)] <- lapply(table1[c(1,2)], as.factor)
A <- ggplot(table1,aes(Gender,Values,fill = Transport)) + geom_bar(stat = "identity",color = "Black", position = 'dodge')+
geom_text(aes(label = Values),
size = 3,
color = "black",
position = position_dodge(width = 0.9),
vjust = -0.2)
table2 <- churn %>% group_by(Transport,MBA) %>% summarise("Values" = n())
table2[c(1,2)] <- lapply(table2[c(1,2)], as.factor)
B <- ggplot(data = table2, aes(MBA,Values, fill = Transport)) + geom_bar(stat = 'identity', position = 'dodge',color = "Black")+
geom_text(aes(label = Values),
size = 3,
vjust = -0.2,
position = position_dodge(width = 0.9))
table3 <- churn %>% group_by(Transport,'License' = license) %>% summarise("Values" = n())
table3[c(1,2)] <- lapply(table3[c(1,2)], as.factor)
C <- ggplot(table3,aes(License,Values,fill = Transport)) + geom_bar(stat = "identity",color = "Black", position = 'dodge')+
geom_text(aes(label = Values),
size = 3,
color = "black",
position = position_dodge(width = 0.9),
vjust = -0.2)
table4 <- churn %>% group_by(Transport,Engineer) %>% summarise("Values" = n())
table4[c(1,2)] <- lapply(table4[c(1,2)], as.factor)
D <- ggplot(data = table4, aes(Engineer,Values, fill = Transport)) + geom_bar(stat = 'identity', position = 'dodge',color = "Black")+
geom_text(aes(label = Values),
size = 3,
vjust = -0.2,
position = position_dodge(width = 0.9))
grid.arrange(A,B,C,D)
#Boxplot
A <- ggplot(data = churn, aes(as.factor(Transport),Age)) + geom_boxplot(color = c("Red","Blue","Green")) + xlab("Transport") + ggtitle("Age vs Transport")
B <- ggplot(data = churn, aes(as.factor(Transport),Work.Exp)) + geom_boxplot(color = c("Red","Blue","Green")) + xlab("Transport") + ggtitle("Work Experience vs Transport")
C <- ggplot(data = churn, aes(as.factor(Transport),Salary)) + geom_boxplot(color = c("Red","Blue","Green")) + xlab("Transport") + ggtitle("Salary vs Transport")
D <- ggplot(data = churn, aes(as.factor(Transport),Distance)) + geom_boxplot(color = c("Red","Blue","Green")) + xlab("Transport") + ggtitle("Distance vs Transport")
grid.arrange(A,B,C,D)
par(mfrow =c(1,1))
#Missing values
any(is.na(churn))
colSums(is.na(churn))
churn <- na.omit(churn)
#Outlier Detection and Treatment
#Cooks distance for outliers detection
cooksd <- cooks.distance(glm(as.numeric(Transport)~.,data = churn))
plot(cooksd,pch="*", cex =1, main ="Cook's Distance", col ="blue")
abline(h = 4*mean(cooksd, na.rm = TRUE), col = "DarkRED",lwd = 2)
#Any value above red line  indicates influential values or outliers
#Treatment using mean imputation method
mydata <- churn[,c(1,5:7)]
Outliers<- mydata[1:60,]
for(i in c(1:4)) {
Outliers[,i] <- NA
Box <-boxplot(mydata[,i],plot =F)$out
if (length(Box)>0){
Outliers[1:length(Box),i] <- Box
}
}
for(i in names(mydata[c(1,2,4)])){
q = quantile(mydata[,i])
mydata[mydata[,i] > q[[4]] + 1.5*(q[[4]] - q[[2]]) ,i ] <- round(q[[4]] + 1.5*(q[[4]] - q[[2]]))
}
q = quantile(mydata[,'Salary'])
mydata[mydata$Salary > q[[4]] + 3*(q[[4]] - q[[2]]),'Salary'] <- round(q[[4]] + 3*(q[[4]] - q[[2]]))
churn <- cbind.data.frame(mydata,churn[,c(2:4,8,9)])
max(churn$Distance)
### Converting dependent variable into 2 levels
churn$Transport <- ifelse(churn$Transport == "Car",1,0)
churn$Transport <- as.factor(churn$Transport)
#Multicollinearity
cor <- cor(churn[c(1:4)])
corrplot.mixed(cor,lower = "number", upper = "pie")
#Variance Inflation Factor
vif(glm(as.numeric(Transport)~., data = churn))
vif(glm(as.numeric(Transport)~. -Work.Exp, data = churn))
#vif < 5. No significant evidence to treat multicollinearity
#-------------------------------------------------------------------
#1. Logistic Regression
#Testing assumptions of logistic regression
#1. Linear relationship b/w log odds and independent variables
model <- train(Transport~., data = churn, method = 'glm')
prob <- predict(model,newdata = churn, type = 'prob')[,1]
mydata <- churn
mydata<- mydata %>% select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(prob/(1-prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
#2.Outliers
#3. Multicollinearity
#Model Formation
log.churn <- churn
set.seed(100)
split <- sample.split(log.churn$Transport,SplitRatio = 0.75)
smote.train <- log.churn[split == TRUE,]
#Handling imbalance dataset
log.train <- SMOTE(Transport ~., smote.train,perc.over = 3000,k = 5,perc.under = 150)
prop.table(table(log.train$Transport))
log.test <- log.churn[split == FALSE,]
ggplot(smote.train) + geom_point(aes(Work.Exp,Salary, col = Transport))
ggplot(smote.train) + geom_point(aes(Distance,Salary, col = Transport))
ggplot(log.train) + geom_point(aes(Distance,Salary, col = Transport))
ggplot(log.train) + geom_point(aes(Distance,Work.Exp, col = Transport))
ggplot(smote.train) + geom_point(aes(Distance,Work.Exp, col = Transport))
ggplot(log.train) + geom_point(aes(Distance,Work.Exp, col = Transport))
ggplot(smote.train) + geom_point(aes(Age,Work.Exp, col = Transport))
ggplot(log.train) + geom_point(aes(Age,Work.Exp, col = Transport))
SA <- ggplot(smote.train) + geom_point(aes(Age,Work.Exp, col = Transport))
SB <- ggplot(log.train) + geom_point(aes(Age,Work.Exp, col = Transport))
grid.arrange(SA,SB)
SB <- ggplot(log.train) + geom_point(aes(Age,Work.Exp, col = Transport)) + ggtitle(('After Smote'))
grid.arrange(SA,SB)
#Visualing the smote analysis
SA <- ggplot(smote.train) + geom_point(aes(Age,Work.Exp, col = Transport)) + ggtitle('Before Smote')
SB <- ggplot(log.train) + geom_point(aes(Age,Work.Exp, col = Transport)) + ggtitle(('After Smote'))
grid.arrange(SA,SB)
summary(churn)
